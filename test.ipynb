{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "959ca15b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 7.861208,
     "end_time": "2022-01-30T05:59:50.466088",
     "exception": false,
     "start_time": "2022-01-30T05:59:42.604880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "import os\n",
    "from collections import Counter\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# Files\n",
    "vocabularyFilename = \"saved_models/latest_vocabulary.csv\";\n",
    "\n",
    "# Read vocabulary data from CSV\n",
    "df = pd.read_csv(vocabularyFilename, sep = '\\t', index_col=0)\n",
    "\n",
    "words = df.loc[0,]\n",
    "word_ids = df.loc[1,].astype('int64')\n",
    "\n",
    "# Create KeyValueTensor\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "\n",
    "# Create lookup table\n",
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)\n",
    "\n",
    "print(\"done\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c18684f9",
   "metadata": {
    "papermill": {
     "duration": 15.761671,
     "end_time": "2022-01-30T06:00:06.234088",
     "exception": false,
     "start_time": "2022-01-30T05:59:50.472417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8649062\n",
      "Result: True\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = keras.models.load_model('saved_models/latest')\n",
    "\n",
    "# Set feature length based on our biggest input vector that was in the training set\n",
    "featureLen = 2470\n",
    "\n",
    "# Test\n",
    "testArr = tf.strings.split(\"I would see this movie again. I thought it was good.\")\n",
    "test = table.lookup(testArr)\n",
    "zero_padding = tf.zeros(featureLen - tf.shape(test)[0], dtype=tf.int64)\n",
    "a_padded = tf.concat([test, zero_padding],0)\n",
    "a_padded = a_padded.numpy().reshape(1,-1);\n",
    "prediction = model(a_padded)\n",
    "print(prediction.numpy()[0][0])\n",
    "print(\"Result:\", prediction.numpy()[0][0] > 0.75)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2689.792157,
   "end_time": "2022-01-30T06:44:22.838914",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-30T05:59:33.046757",
   "version": "2.3.3"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
