{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "959ca15b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 7.861208,
     "end_time": "2022-01-30T05:59:50.466088",
     "exception": false,
     "start_time": "2022-01-30T05:59:42.604880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 14:11:22.731210: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-05 14:11:22.731305: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words: [('the', 112780), ('a', 61522), ('and', 60362), ('of', 56663), ('to', 52397), ('is', 40621), ('in', 34059), ('I', 26135), ('that', 25365), ('this', 23018)]\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 14:11:28.974738: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-05 14:11:28.974873: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-05 14:11:28.974946: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (penguin): /proc/driver/nvidia/version does not exist\n",
      "2022-02-05 14:11:28.976073: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "filename = \"./Train.csv\"\n",
    "df = pd.read_csv(filename, usecols=['text', 'label'], dtype={'text': 'str', 'label': 'int64'})\n",
    "dfX = df.loc[:, 'text']\n",
    "dfY = df.loc[:, 'label']\n",
    "dfX = dfX[:10000]\n",
    "dfY = dfY[:10000]\n",
    "\n",
    "vocabulary = Counter()\n",
    "for title in dfX:\n",
    "    words = title.split()\n",
    "    validWords = filter(lambda x: len(x) <= 14, words)\n",
    "    vocabulary.update(validWords)\n",
    "\n",
    "# Truncate vocabulary\n",
    "vocab_size = 1000\n",
    "truncatedVocabulary = [word for word, count in vocabulary.most_common()[:vocab_size]]\n",
    "\n",
    "# Print out the 10 most common words and the number of times they occur\n",
    "print(\"Most common words:\", vocabulary.most_common()[:10])\n",
    "\n",
    "# Convert words to tensor\n",
    "words = tf.constant(truncatedVocabulary)\n",
    "\n",
    "# Assign each word an ID\n",
    "word_ids = tf.range(len(truncatedVocabulary), dtype=tf.int64)\n",
    "\n",
    "# Create KeyValueTensor\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "\n",
    "# Create lookup table\n",
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)\n",
    "\n",
    "# Test the lookup table\n",
    "#testArr = \"China and Iraq are in the dataset\".split()\n",
    "#testRes = table.lookup(tf.constant(testArr))\n",
    "#print(\"Test result:\", testRes)\n",
    "\n",
    "print(\"done\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c18684f9",
   "metadata": {
    "papermill": {
     "duration": 15.761671,
     "end_time": "2022-01-30T06:00:06.234088",
     "exception": false,
     "start_time": "2022-01-30T05:59:50.472417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2470)\n",
      "(10000,)\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 14:12:03.880993: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 98800000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Convert sentences to arrays of word ids\n",
    "data = []\n",
    "for title in dfX:\n",
    "    sample = tf.strings.split(title)\n",
    "    processed = table.lookup(sample)\n",
    "    data.append(processed.numpy())\n",
    "\n",
    "# Create a ragged tensor and then convert it to a padded dense tensor\n",
    "ragged = tf.ragged.constant(data)\n",
    "ragged = ragged.to_tensor(default_value=0)\n",
    "\n",
    "# Make dataset\n",
    "features = tf.constant(ragged)\n",
    "print(features.shape)\n",
    "labels = tf.constant(dfY)\n",
    "print(labels.shape)\n",
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices((features, labels)).batch(32).prefetch(1)\n",
    "#print(train_set)\n",
    "\n",
    "#print(next(train_set.batch(32).as_numpy_iterator())[0][0])\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb8954",
   "metadata": {
    "papermill": {
     "duration": 2651.367693,
     "end_time": "2022-01-30T06:44:17.608410",
     "exception": false,
     "start_time": "2022-01-30T06:00:06.240717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 14:12:05.826068: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 98800000 exceeds 10% of free system memory.\n",
      "2022-02-05 14:12:05.971608: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 98800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 14:12:12.903489: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 40468480 exceeds 10% of free system memory.\n",
      "2022-02-05 14:12:13.097999: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 40468480 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/313 [..............................] - ETA: 42:12 - loss: 0.6900 - accuracy: 0.5312"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "embed_size = 128\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size, input_shape=[None], mask_zero=True),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.GRU(128),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, batch_size=32, epochs=5)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8c2e9",
   "metadata": {
    "papermill": {
     "duration": 1.021375,
     "end_time": "2022-01-30T06:44:18.867259",
     "exception": false,
     "start_time": "2022-01-30T06:44:17.845884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testArr = tf.strings.split(\"This was pretty much my favorite movie ive ever seen\")\n",
    "test = table.lookup(testArr)\n",
    "zero_padding = tf.zeros(tf.shape(features)[1] - tf.shape(test)[0], dtype=tf.int64)\n",
    "a_padded = tf.concat([test, zero_padding],0)\n",
    "a_padded = a_padded.numpy().reshape(1,-1);\n",
    "#print(\"Prediction input: \", a_padded)\n",
    "prediction = model.predict(a_padded)\n",
    "print(prediction)\n",
    "print(\"Positive:\", prediction[0] > 0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d643d3",
   "metadata": {
    "papermill": {
     "duration": 0.241681,
     "end_time": "2022-01-30T06:44:19.345135",
     "exception": false,
     "start_time": "2022-01-30T06:44:19.103454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2689.792157,
   "end_time": "2022-01-30T06:44:22.838914",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-30T05:59:33.046757",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
